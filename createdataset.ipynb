{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from tpot import TPOTClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, GRU, LSTM, Dense, Dropout\n",
    "from keras.initializers import Constant\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import pickle as pkl\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>TweetID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SScore</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>EScore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-30 23:29:15+00:00</td>\n",
       "      <td>1575991191170342912</td>\n",
       "      <td>@Logitech @apple @Google @Microsoft @Dell @Len...</td>\n",
       "      <td>ManjuSreedaran</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.853283</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>0.587121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-30 21:46:35+00:00</td>\n",
       "      <td>1575965354425131008</td>\n",
       "      <td>@MK_habit_addict @official_stier @MortalKombat...</td>\n",
       "      <td>MiKeMcDnet</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.519470</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.886913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-30 21:18:02+00:00</td>\n",
       "      <td>1575958171423752203</td>\n",
       "      <td>As @CRN celebrates its 40th anniversary, Bob F...</td>\n",
       "      <td>jfollett</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.763791</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.960347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-30 20:05:24+00:00</td>\n",
       "      <td>1575939891485032450</td>\n",
       "      <td>@dell your customer service is horrible especi...</td>\n",
       "      <td>daveccarr</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.954023</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.983203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-30 20:03:17+00:00</td>\n",
       "      <td>1575939359160750080</td>\n",
       "      <td>@zacokalo @Dell @DellCares @Dell give the man ...</td>\n",
       "      <td>heycamella</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.529170</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.776124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        DateTime              TweetID  \\\n",
       "Index                                                   \n",
       "0      2022-09-30 23:29:15+00:00  1575991191170342912   \n",
       "1      2022-09-30 21:46:35+00:00  1575965354425131008   \n",
       "2      2022-09-30 21:18:02+00:00  1575958171423752203   \n",
       "3      2022-09-30 20:05:24+00:00  1575939891485032450   \n",
       "4      2022-09-30 20:03:17+00:00  1575939359160750080   \n",
       "\n",
       "                                                    Text        Username  \\\n",
       "Index                                                                      \n",
       "0      @Logitech @apple @Google @Microsoft @Dell @Len...  ManjuSreedaran   \n",
       "1      @MK_habit_addict @official_stier @MortalKombat...      MiKeMcDnet   \n",
       "2      As @CRN celebrates its 40th anniversary, Bob F...        jfollett   \n",
       "3      @dell your customer service is horrible especi...       daveccarr   \n",
       "4      @zacokalo @Dell @DellCares @Dell give the man ...      heycamella   \n",
       "\n",
       "      Sentiment    SScore       Emotion    EScore  \n",
       "Index                                              \n",
       "0       neutral  0.853283  anticipation  0.587121  \n",
       "1       neutral  0.519470           joy  0.886913  \n",
       "2      positive  0.763791           joy  0.960347  \n",
       "3      negative  0.954023         anger  0.983203  \n",
       "4       neutral  0.529170         anger  0.776124  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"FullyLabelled/sentiment-emotion-labelled_Dell_tweets.csv\", index_col=\"Index\")\n",
    "df.columns=[\"DateTime\", \"TweetID\", \"Text\", \"Username\", \"Sentiment\", \"SScore\", \"Emotion\",\"EScore\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SScore</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>EScore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Logitech @apple @Google @Microsoft @Dell @Len...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.853283</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>0.587121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@MK_habit_addict @official_stier @MortalKombat...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.519470</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.886913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As @CRN celebrates its 40th anniversary, Bob F...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.763791</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.960347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@dell your customer service is horrible especi...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.954023</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.983203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@zacokalo @Dell @DellCares @Dell give the man ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.529170</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.776124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text Sentiment    SScore  \\\n",
       "Index                                                                          \n",
       "0      @Logitech @apple @Google @Microsoft @Dell @Len...   neutral  0.853283   \n",
       "1      @MK_habit_addict @official_stier @MortalKombat...   neutral  0.519470   \n",
       "2      As @CRN celebrates its 40th anniversary, Bob F...  positive  0.763791   \n",
       "3      @dell your customer service is horrible especi...  negative  0.954023   \n",
       "4      @zacokalo @Dell @DellCares @Dell give the man ...   neutral  0.529170   \n",
       "\n",
       "            Emotion    EScore  \n",
       "Index                          \n",
       "0      anticipation  0.587121  \n",
       "1               joy  0.886913  \n",
       "2               joy  0.960347  \n",
       "3             anger  0.983203  \n",
       "4             anger  0.776124  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([\"DateTime\", \"TweetID\", \"Username\"], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['neutral', 'positive', 'negative'], dtype=object),\n",
       " array(['anticipation', 'joy', 'anger', 'sadness', 'fear', 'optimism',\n",
       "        'disgust', 'surprise'], dtype=object))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sentiment.unique(), df.Emotion.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sentiment\n",
       " negative    10556\n",
       " positive     7366\n",
       " neutral      7048\n",
       " Name: count, dtype: int64,\n",
       " Emotion\n",
       " anger           7520\n",
       " joy             6326\n",
       " anticipation    5171\n",
       " disgust         3000\n",
       " sadness         1328\n",
       " optimism        1225\n",
       " fear             366\n",
       " surprise          34\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sentiment.value_counts(), df.Emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SScore</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>EScore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Logitech @apple @Google @Microsoft @Dell @Len...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.853283</td>\n",
       "      <td>7</td>\n",
       "      <td>0.587121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@MK_habit_addict @official_stier @MortalKombat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.519470</td>\n",
       "      <td>6</td>\n",
       "      <td>0.886913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As @CRN celebrates its 40th anniversary, Bob F...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.763791</td>\n",
       "      <td>6</td>\n",
       "      <td>0.960347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@dell your customer service is horrible especi...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.954023</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@zacokalo @Dell @DellCares @Dell give the man ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529170</td>\n",
       "      <td>1</td>\n",
       "      <td>0.776124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Sentiment    SScore  \\\n",
       "Index                                                                           \n",
       "0      @Logitech @apple @Google @Microsoft @Dell @Len...          1  0.853283   \n",
       "1      @MK_habit_addict @official_stier @MortalKombat...          1  0.519470   \n",
       "2      As @CRN celebrates its 40th anniversary, Bob F...          0  0.763791   \n",
       "3      @dell your customer service is horrible especi...          2  0.954023   \n",
       "4      @zacokalo @Dell @DellCares @Dell give the man ...          1  0.529170   \n",
       "\n",
       "       Emotion    EScore  \n",
       "Index                     \n",
       "0            7  0.587121  \n",
       "1            6  0.886913  \n",
       "2            6  0.960347  \n",
       "3            1  0.983203  \n",
       "4            1  0.776124  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdict={'neutral':1, 'positive':0, 'negative':2}\n",
    "edict={'disgust':0,'anger':1, 'sadness':2, 'fear':3,'surprise':4, 'optimism':5, 'joy':6,'anticipation':7}\n",
    "df.Sentiment=df.Sentiment.replace(sdict)\n",
    "df.Emotion=df.Emotion.replace(edict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    return text\n",
    "\n",
    "df.Text=df.Text.apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index\n",
       "0     @Logitech @apple @Google @Microsoft @Dell @Len...\n",
       "1     @MK_habit_addict @official_stier @MortalKombat...\n",
       "2     As @CRN celebrates its 40th anniversary, Bob F...\n",
       "3     @dell your customer service is horrible especi...\n",
       "4     @zacokalo @Dell @DellCares @Dell give the man ...\n",
       "5     The screenshot is acting up from the website o...\n",
       "6     @emijuju_ @Alienware @Dell @IntelGaming alien ...\n",
       "7     COOKING STREAM DAY!!! Ty to @Alienware for spo...\n",
       "8      @emijuju_ @Alienware @Dell @intel Beautiful 😍❤️😻\n",
       "9     What's your biggest data management challenge?...\n",
       "10    What does it take to delight stakeholders with...\n",
       "11    @BigwillUK @Alienware @Dell Good idea. I'll pu...\n",
       "12    @teksyndicate @Alienware @Dell Looks great, ho...\n",
       "13    Steve Gorman takes you through Part 2 of Explo...\n",
       "14    Indian's decision to give incentives to @Apple...\n",
       "15    I am Steve, a Geek. I am the CEO of @TheGeekVi...\n",
       "16      @siim_kuusik @Alienware @Dell Because 3840x1600\n",
       "17         ummm @Dell ...your customer service is trash\n",
       "18    Steve Gorman takes you through Part 2 of Explo...\n",
       "19    This week we were at the \"Top Gun\" themed @Del...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Text.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text2(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    processed_text = []\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            stemmed_word = stemmer.stem(word)\n",
    "            lemmatized_word = lemmatizer.lemmatize(stemmed_word)\n",
    "            processed_words.append(lemmatized_word)\n",
    "\n",
    "    processed_text.append(' '.join(processed_words))\n",
    "\n",
    "    return processed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index\n",
       "0     [@ logitech @ appl @ googl @ microsoft @ dell ...\n",
       "1     [@ mk_habit_addict @ official_sti @ mortalkomb...\n",
       "2     [a @ crn celebr 40th anniversari , bob faletra...\n",
       "3     [@ dell custom servic horribl especi agent sye...\n",
       "4     [@ zacokalo @ dell @ dellcar @ dell give man p...\n",
       "5     [the screenshot act websit @ googl @ dell lati...\n",
       "6     [@ emijuju_ @ alienwar @ dell @ intelgam alien...\n",
       "7     [cook stream day ! ! ! ty @ alienwar sponsor s...\n",
       "8     [@ emijuju_ @ alienwar @ dell @ intel beauti 😍...\n",
       "9     [what 's biggest data manag challeng ? • cloud...\n",
       "10    [what take delight stakehold onlin experi ? th...\n",
       "11    [@ bigwilluk @ alienwar @ dell good idea . i '...\n",
       "12    [@ teksynd @ alienwar @ dell look great , hope...\n",
       "13    [steve gorman take part 2 explor @ f5 big-ip v...\n",
       "14    [indian 's decis give incent @ appl @ dell bri...\n",
       "15    [i steve , geek . i ceo @ thegeekvillag . talk...\n",
       "16    [@ siim_kuusik @ alienwar @ dell becaus 3840x1...\n",
       "17                [ummm @ dell ... custom servic trash]\n",
       "18    [steve gorman take part 2 explor @ f5 big-ip v...\n",
       "19    [thi week `` top gun '' theme @ dell product e...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Text=df.Text.apply(process_text2)\n",
    "df.Text.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7806934, 12538260)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = df['Text'].tolist()\n",
    "tokenized_tweets = [tweet[0].split() for tweet in tweets]\n",
    "\n",
    "modelw2v = Word2Vec(tokenized_tweets, vector_size=300, window=5, min_count=10, workers=8)\n",
    "modelw2v.train(tokenized_tweets, total_examples=len(tokenized_tweets), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('intellig', 0.6653841137886047),\n",
       " ('analyt', 0.62935870885849),\n",
       " ('real-tim', 0.614263117313385),\n",
       " ('iot', 0.612145185470581),\n",
       " ('edgecomput', 0.6081886291503906),\n",
       " ('➡️', 0.6026829481124878),\n",
       " ('multicloud', 0.6022351384162903),\n",
       " ('workshop', 0.6001420021057129),\n",
       " ('digitaltransform', 0.5979998111724854),\n",
       " ('machinelearn', 0.590273916721344)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelw2v.wv.most_similar(\"ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.Text\n",
    "y = df.drop(['Text'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=df[\"Emotion\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Emotion\n",
       " 1    752\n",
       " 6    633\n",
       " 7    517\n",
       " 0    300\n",
       " 2    133\n",
       " 5    122\n",
       " 3     37\n",
       " 4      3\n",
       " Name: count, dtype: int64,\n",
       " Emotion\n",
       " 1    6768\n",
       " 6    5693\n",
       " 7    4654\n",
       " 0    2700\n",
       " 2    1195\n",
       " 5    1103\n",
       " 3     329\n",
       " 4      31\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.Emotion.value_counts(), y_train.Emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vec(s, model):\n",
    "    # return np.array([model.wv[word] for word in s[0].split() if word in modelw2v.wv.key_to_index])\n",
    "    vecs = [model.wv[word] for word in s[0].split() if word in model.wv.key_to_index]\n",
    "    return np.mean(vecs, axis=0) if vecs else np.zeros(model.vector_size)\n",
    "X_train_vec = [sentence_to_vec(s, modelw2v) for s in X_train]\n",
    "X_test_vec = [sentence_to_vec(s, modelw2v) for s in X_test]\n",
    "\n",
    "max_len = max(max(len(x) for x in X_train_vec), max(len(x) for x in X_test_vec))\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_vec, maxlen=max_len, dtype='float32', padding='post')\n",
    "X_test_pad = pad_sequences(X_test_vec, maxlen=max_len, dtype='float32', padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2497, 300), (2497, 4))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {\n",
    "#     'Voting Classifier': VotingClassifier(estimators=[\n",
    "#         ('xg', XGBClassifier(use_label_encoder=False, eval_metric='logloss', verbosity=0)),\n",
    "#         ('lgbm', LGBMClassifier(verbose=0, random_state=42)),\n",
    "#         ('hgb', HistGradientBoostingClassifier(random_state=42))\n",
    "#     ], voting='hard'),\n",
    "#     'Logistic Regression': LogisticRegression(verbose=0, max_iter=1000),\n",
    "#     'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "#     'Random Forest': RandomForestClassifier(verbose=0, random_state=42),\n",
    "#     'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "#     'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', verbosity=0),\n",
    "#     'CatBoost': CatBoostClassifier(verbose=0, random_seed=42),\n",
    "#     'LightGBM': LGBMClassifier(verbose=0, random_state=42),\n",
    "#     'HistGradientBoosting': HistGradientBoostingClassifier(random_state=42)\n",
    "#     # 'TPOT': TPOTClassifier(generations=5, population_size=50, verbosity=0, random_state=42)\n",
    "# }\n",
    "\n",
    "# y_trains = np.array(y_train.Sentiment).reshape(-1,)\n",
    "\n",
    "# for model_name, model in models.items():\n",
    "#     print(f\"Training {model_name}...\")\n",
    "#     model.fit(X_train_pad, y_trains)\n",
    "    \n",
    "#     print(f\"Evaluating {model_name}...\")\n",
    "#     y_pred = model.predict(X_test_pad)\n",
    "#     print(classification_report(y_test.Sentiment, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_size = len(modelw2v.wv.key_to_index) + 1\n",
    "# vector_size = modelw2v.wv.vector_size\n",
    "\n",
    "# embedding_matrix = np.zeros((vocab_size, vector_size))\n",
    "# for word, i in modelw2v.wv.key_to_index.items():\n",
    "#     embedding_matrix[i] = modelw2v.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(model_type):\n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(vocab_size, vector_size, embeddings_initializer=Constant(embedding_matrix), trainable=True))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     if model_type == 'RNN':\n",
    "#         model.add(SimpleRNN(50))\n",
    "#     elif model_type == 'GRU':\n",
    "#         model.add(GRU(50))\n",
    "#     elif model_type == 'LSTM':\n",
    "#         model.add(LSTM(50))\n",
    "    \n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model_type in ['RNN', 'GRU', 'LSTM']:\n",
    "#     print(f\"Training {model_type} model...\")\n",
    "#     model = create_model(model_type)\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     model.fit(X_train_pad, y_trains, epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modele = {\n",
    "#     'Logistic Regression': LogisticRegression(verbose=0, max_iter=1000),\n",
    "#     'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "#     'Random Forest': RandomForestClassifier(verbose=0, random_state=42),\n",
    "#     'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "#     'Voting Classifier': VotingClassifier(estimators=[\n",
    "#         ('xg', XGBClassifier(use_label_encoder=False, eval_metric='logloss', verbosity=0)),\n",
    "#         ('lgbm', LGBMClassifier(verbose=0, random_state=42)),\n",
    "#         ('hgb', HistGradientBoostingClassifier(random_state=42))\n",
    "#     ], voting='hard'),\n",
    "#     'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', verbosity=0),\n",
    "#     'CatBoost': CatBoostClassifier(verbose=0, random_seed=42),\n",
    "#     'LightGBM': LGBMClassifier(verbose=0, random_state=42),\n",
    "#     'HistGradientBoosting': HistGradientBoostingClassifier(random_state=42)\n",
    "#     # 'TPOT': TPOTClassifier(generations=5, population_size=50, verbosity=0, random_state=42)\n",
    "# }\n",
    "\n",
    "# y_trains = np.array(y_train.Emotion).reshape(-1,)\n",
    "\n",
    "# for model_name, model in modele.items():\n",
    "#     print(f\"Training {model_name}...\")\n",
    "#     model.fit(X_train_pad, y_trains)\n",
    "    \n",
    "#     print(f\"Evaluating {model_name}...\")\n",
    "#     y_pred = model.predict(X_test_pad)\n",
    "#     print(classification_report(y_test.Emotion, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modele = {\n",
    "#     'Linear Regression': LinearRegression(),\n",
    "#     'Decision Tree Regressor': DecisionTreeRegressor(random_state=42),\n",
    "#     'Random Forest Regressor': RandomForestRegressor(random_state=42),\n",
    "#     'AdaBoost Regressor': AdaBoostRegressor(random_state=42),\n",
    "#     'Gradient Boosting Regressor': GradientBoostingRegressor(random_state=42),\n",
    "#     'XGBoost Regressor': XGBRegressor(use_label_encoder=False, eval_metric='logloss', verbosity=0),\n",
    "#     'CatBoost Regressor': CatBoostRegressor(verbose=0, random_seed=42),\n",
    "#     'LightGBM Regressor': LGBMRegressor(random_state=42)\n",
    "# }\n",
    "\n",
    "# y_trains = np.array(y_train.SScore).reshape(-1,)\n",
    "\n",
    "# for model_name, model in modele.items():\n",
    "#     print(f\"Training {model_name}...\")\n",
    "#     model.fit(X_train_pad, y_trains)\n",
    "    \n",
    "#     print(f\"Evaluating {model_name}...\")\n",
    "#     y_pred = model.predict(X_test_pad)\n",
    "#     print('Mean Squared Error:', mean_squared_error(y_test.SScore, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modele = {\n",
    "#     'Linear Regression': LinearRegression(),\n",
    "#     'Decision Tree Regressor': DecisionTreeRegressor(random_state=42),\n",
    "#     'Random Forest Regressor': RandomForestRegressor(random_state=42),\n",
    "#     'AdaBoost Regressor': AdaBoostRegressor(random_state=42),\n",
    "#     'Gradient Boosting Regressor': GradientBoostingRegressor(random_state=42),\n",
    "#     'XGBoost Regressor': XGBRegressor(use_label_encoder=False, eval_metric='logloss', verbosity=0),\n",
    "#     'CatBoost Regressor': CatBoostRegressor(verbose=0, random_seed=42),\n",
    "#     'LightGBM Regressor': LGBMRegressor(random_state=42)\n",
    "# }\n",
    "\n",
    "# y_trains = np.array(y_train.EScore).reshape(-1,)\n",
    "\n",
    "# for model_name, model in modele.items():\n",
    "#     print(f\"Training {model_name}...\")\n",
    "#     model.fit(X_train_pad, y_trains)\n",
    "    \n",
    "#     print(f\"Evaluating {model_name}...\")\n",
    "#     y_pred = model.predict(X_test_pad)\n",
    "#     print('Mean Squared Error:', mean_squared_error(y_test.EScore, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.system(f'cp {\"FullyLabelled/sentiment-emotion-labelled_Dell_tweets.csv\"} {\"TempSmall.csv\"}')\n",
    "# os.system(f'cp {\"SemiLabelled/training.1600000.processed.noemoticon.csv\"} {\"TempLarge.csv\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small=pd.read_csv(\"TempSmall.csv\", index_col=\"Index\")\n",
    "# small.columns=[\"DateTime\", \"TweetID\", \"Text\", \"Username\", \"Sentiment\", \"SScore\", \"Emotion\",\"EScore\"]\n",
    "# small.drop([\"DateTime\", \"TweetID\", \"Username\"], axis=1, inplace=True)\n",
    "# small.Sentiment=small.Sentiment.replace(sdict)\n",
    "# small.Emotion=small.Emotion.replace(edict)\n",
    "# small.Text=small.Text.apply(process_text)\n",
    "# small.Text=small.Text.apply(process_text2)\n",
    "\n",
    "# large=pd.read_csv(\"TempLarge.csv\", names=[\"Sentiment\", \"ID2\", \"DT\", \"Q\", \"UserName\", \"Text\"], encoding=\"ISO-8859-1\")\n",
    "# large.drop([\"DT\", \"ID2\", \"UserName\", \"Q\"], axis=1, inplace=True)\n",
    "# large.Sentiment=large.Sentiment.replace({0:2, 4:0,2:1})\n",
    "# large.Text=large.Text.apply(process_text)\n",
    "# large.Text=large.Text.apply(process_text2)\n",
    "\n",
    "# small.to_csv(\"TempSmall.csv\")\n",
    "# large.to_csv(\"TempLarge.csv\")\n",
    "\n",
    "# tweets = small['Text'].tolist()+large['Text'].tolist()\n",
    "# tokenized_tweets = [tweet[0].split() for tweet in tweets]\n",
    "\n",
    "# modelw2v = Word2Vec(tokenized_tweets, vector_size=300, window=5, min_count=10, workers=8)\n",
    "# modelw2v.train(tokenized_tweets, total_examples=len(tokenized_tweets), epochs=20)\n",
    "\n",
    "# pkl.dump(modelw2v, open(\"W2V_Model.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_vec = [sentence_to_vec(s, modelw2v) for s in small.Text]\n",
    "X_test_vec = [sentence_to_vec(s, modelw2v) for s in large.Text]\n",
    "\n",
    "max_len = max(max(len(x) for x in X_train_vec), max(len(x) for x in X_test_vec))\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_vec, maxlen=max_len, dtype='float32', padding='post')\n",
    "X_test_pad = pad_sequences(X_test_vec, maxlen=max_len, dtype='float32', padding='post')\n",
    "\n",
    "y_train=small.drop([\"Text\"])\n",
    "y_test=large.drop([\"Text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_optimization(cv_splits, X, y, mode=1):\n",
    "    def function(learning_rate, depth, l2_leaf_reg, border_count):\n",
    "        if mode:\n",
    "            return cross_val_score(\n",
    "                CatBoostClassifier(\n",
    "                    learning_rate=learning_rate,\n",
    "                    depth=int(round(depth)),\n",
    "                    l2_leaf_reg=l2_leaf_reg,\n",
    "                    border_count=int(round(border_count)),\n",
    "                    loss_function=\"Logloss\",\n",
    "                    verbose=False,\n",
    "                ),\n",
    "                X=X,\n",
    "                y=y,\n",
    "                cv=cv_splits,\n",
    "                scoring=\"accuracy\",\n",
    "                n_jobs=-1,\n",
    "            ).mean()\n",
    "        else:\n",
    "            return cross_val_score(\n",
    "                CatBoostRegressor(\n",
    "                    learning_rate=learning_rate,\n",
    "                    depth=int(round(depth)),\n",
    "                    l2_leaf_reg=l2_leaf_reg,\n",
    "                    border_count=int(round(border_count)),\n",
    "                    loss_function=\"Logloss\",\n",
    "                    verbose=False,\n",
    "                ),\n",
    "                X=X,\n",
    "                y=y,\n",
    "                cv=cv_splits,\n",
    "                scoring=\"accuracy\",\n",
    "                n_jobs=-1,\n",
    "            ).mean()\n",
    "\n",
    "    return function\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(X_test_pad) > 0:\n",
    "    models = {\n",
    "        \"Sentiment\": CatBoostClassifier(verbose=False),\n",
    "        \"Emotion\": CatBoostClassifier(verbose=False),\n",
    "        \"SScore\": CatBoostRegressor(verbose=False),\n",
    "        \"EScore\": CatBoostRegressor(verbose=False),\n",
    "    }\n",
    "\n",
    "    for label in models.keys():\n",
    "        if label==\"SScore\" or label==\"EScore\":\n",
    "            mode=0\n",
    "        else:\n",
    "            mode=1\n",
    "        optimizer = BayesianOptimization(\n",
    "            f=catboost_optimization(5, X_train_pad, y_train[label], mode),\n",
    "            pbounds={\n",
    "                \"learning_rate\": (0.01, 1.0),\n",
    "                \"depth\": (4, 10),\n",
    "                \"l2_leaf_reg\": (1, 10),\n",
    "                \"border_count\": (5, 255)\n",
    "            },\n",
    "            random_state=1234,\n",
    "            verbose=2\n",
    "        )\n",
    "\n",
    "        optimizer.maximize(n_iter=25, init_points=2)\n",
    "        params=optimizer.max[\"params\"]\n",
    "        if mode:\n",
    "            m=CatBoostClassifier(**params)\n",
    "        else:\n",
    "            m=CatBoostRegressor(**params)\n",
    "        \n",
    "        m.fit(X_train_pad, y_train[label])\n",
    "        \n",
    "        models[label]=m\n",
    "\n",
    "    \n",
    "    predictions = {}\n",
    "    for label in models.keys():\n",
    "        predictions[label] = models[label].predict_proba(X_test_pad)\n",
    "\n",
    "    indices = np.where(\n",
    "        (predictions[\"Sentiment\"][:, 1] > 0.9)\n",
    "        & (predictions[\"Emotion\"][:, 1] > 0.9)\n",
    "        & (predictions[\"SScore\"][:, 1] > 0.9)\n",
    "        & (predictions[\"EScore\"][:, 1] > 0.9)\n",
    "    )\n",
    "\n",
    "    X_train_pad = np.concatenate((X_train_pad, X_test_pad[indices]))\n",
    "    y_train[\"Sentiment\"] = np.concatenate(\n",
    "        (y_train[\"Sentiment\"], predictions[\"Sentiment\"][indices, 1])\n",
    "    )\n",
    "    y_train[\"Emotion\"] = np.concatenate(\n",
    "        (y_train[\"Emotion\"], predictions[\"Emotion\"][indices, 1])\n",
    "    )\n",
    "    y_train[\"SScore\"] = np.concatenate(\n",
    "        (y_train[\"SScore\"], predictions[\"SScore\"][indices, 1])\n",
    "    )\n",
    "    y_train[\"EScore\"] = np.concatenate(\n",
    "        (y_train[\"EScore\"], predictions[\"EScore\"][indices, 1])\n",
    "    )\n",
    "\n",
    "    X_test_pad = np.delete(X_test_pad, indices, axis=0)\n",
    "    y_test=np.delete(y_test, indices, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in models.keys():\n",
    "        models[label].fit(X_train_pad, y_train[label])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
